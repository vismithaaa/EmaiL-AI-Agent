{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FDPgaevdeNQ",
        "outputId": "9e3375cd-6500-4a17-d34f-1db0f9632969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install crewai langchain-groq duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEIeTK_9uFvL",
        "outputId": "4923c829-d9f8-4d7d-83eb-fdfdc5dd560e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: crewai\n",
            "Version: 0.28.8\n",
            "Summary: Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.\n",
            "Home-page: \n",
            "Author: Joao Moura\n",
            "Author-email: joao@crewai.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: appdirs, click, embedchain, instructor, langchain, openai, opentelemetry-api, opentelemetry-exporter-otlp-proto-http, opentelemetry-sdk, pydantic, python-dotenv, regex\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show crewai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYH3vJxvjVve"
      },
      "source": [
        "# The goal\n",
        "\n",
        "Reply to a customer email\n",
        "1. get the email\n",
        "2. categorize this as a \"sales\", \"custom enquiry\", \"off topic\", \"customer complaint\"\n",
        "3. use the category to research info needed for the reply\n",
        "4. take the info and check if there is enough to answer the email\n",
        "5. write a reply\n",
        "6. check the reply\n",
        "7. save the email\n",
        "\n",
        "### Agents\n",
        "- categorizer\n",
        "- researcher (web for now would be internal RAG)\n",
        "- email writer\n",
        "\n",
        "\n",
        "### Tasks\n",
        "- categorize email\n",
        "- research the answer\n",
        "- write the email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwtCqJJmu085"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMAPjXCXcd8a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9kHdE8Na8i4"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvdcABrTa-rR"
      },
      "outputs": [],
      "source": [
        "import json  # Import the JSON module to parse JSON strings\n",
        "from langchain_core.agents import AgentFinish\n",
        "\n",
        "agent_finishes  = []\n",
        "\n",
        "import json\n",
        "from typing import Union, List, Tuple, Dict\n",
        "from langchain.schema import AgentFinish\n",
        "\n",
        "call_number = 0\n",
        "\n",
        "def print_agent_output(agent_output: Union[str, List[Tuple[Dict, str]], AgentFinish], agent_name: str = 'Generic call'):\n",
        "    global call_number  # Declare call_number as a global variable\n",
        "    call_number += 1\n",
        "    with open(\"crew_callback_logs.txt\", \"a\") as log_file:\n",
        "        # Try to parse the output if it is a JSON string\n",
        "        if isinstance(agent_output, str):\n",
        "            try:\n",
        "                agent_output = json.loads(agent_output)  # Attempt to parse the JSON string\n",
        "            except json.JSONDecodeError:\n",
        "                pass  # If there's an error, leave agent_output as is\n",
        "\n",
        "        # Check if the output is a list of tuples as in the first case\n",
        "        if isinstance(agent_output, list) and all(isinstance(item, tuple) for item in agent_output):\n",
        "            print(f\"-{call_number}----Dict------------------------------------------\", file=log_file)\n",
        "            for action, description in agent_output:\n",
        "                # Print attributes based on assumed structure\n",
        "                print(f\"Agent Name: {agent_name}\", file=log_file)\n",
        "                print(f\"Tool used: {getattr(action, 'tool', 'Unknown')}\", file=log_file)\n",
        "                print(f\"Tool input: {getattr(action, 'tool_input', 'Unknown')}\", file=log_file)\n",
        "                print(f\"Action log: {getattr(action, 'log', 'Unknown')}\", file=log_file)\n",
        "                print(f\"Description: {description}\", file=log_file)\n",
        "                print(\"--------------------------------------------------\", file=log_file)\n",
        "\n",
        "        # Check if the output is a dictionary as in the second case\n",
        "        elif isinstance(agent_output, AgentFinish):\n",
        "            print(f\"-{call_number}----AgentFinish---------------------------------------\", file=log_file)\n",
        "            print(f\"Agent Name: {agent_name}\", file=log_file)\n",
        "            agent_finishes.append(agent_output)\n",
        "            # Extracting 'output' and 'log' from the nested 'return_values' if they exist\n",
        "            output = agent_output.return_values\n",
        "            # log = agent_output.get('log', 'No log available')\n",
        "            print(f\"AgentFinish Output: {output['output']}\", file=log_file)\n",
        "            # print(f\"Log: {log}\", file=log_file)\n",
        "            # print(f\"AgentFinish: {agent_output}\", file=log_file)\n",
        "            print(\"--------------------------------------------------\", file=log_file)\n",
        "\n",
        "        # Handle unexpected formats\n",
        "        else:\n",
        "            # If the format is unknown, print out the input directly\n",
        "            print(f\"-{call_number}-Unknown format of agent_output:\", file=log_file)\n",
        "            print(type(agent_output), file=log_file)\n",
        "            print(agent_output, file=log_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTpHg054ayis"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzWrf9n6adVo"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "GROQ_LLM = ChatGroq(\n",
        "            # api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "            model=\"llama3-70b-8192\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G40lprgkCJ2"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYA43C0An6tn"
      },
      "outputs": [],
      "source": [
        "from crewai import Crew, Agent, Task, Process\n",
        "from langchain_community.tools import DuckDuckGoSearchRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3GvksYIkA1m"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from random import randint\n",
        "from langchain.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc8SeVoUn5Q6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import requests\n",
        "from langchain.tools import tool\n",
        "\n",
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "search_tool = DuckDuckGoSearchRun()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Nvbxjcy8jJ56",
        "outputId": "c46e6db9-04ea-4f56-c63c-e06f4a686b66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Feitian ePass K9 USB Security Key offers all the features expected from a security key at an affordable price. Feitian ePass K9 USB Security Key f ... The USB-C key is best suited for ... But its $286 asking price on Amazon (and even crazier $334 price directly from Corsair) feels like a bomb on your credit card bill. ... USB-C - USB-A - USB 3.2 Gen 2 (compatibel met PS4/PS5 ... Best security. 7. Kingston IronKey Keypad 200. View at Amazon. View at Amazon. View at Newegg. The best USB flash drive for security This ultra secure flash drive features USB 3.2 Gen 1 speeds and ... We've reviewed our recommendations and have updated our best hardware security key overall. Yubico Security Key C NFC. Best Overall Security Key. $29 at Amazon. YubiKey 5 NFC USB-A. Best Premium Security Key. $50 at Amazon. Kensington VeriMark Guard. Best Security for Bio-Authentication. Offered in USB-A or USB-C models, in sizes ranging from 8 GB to 256 GB, this drive comes with a five-year warranty. Connector: USB 3.2 Gen 1 Type-A or Type C $92 at Amazon\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "search_tool.run(\"usb key price\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FhZyiMakLNL"
      },
      "source": [
        "## Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hbe-5rH_nHqf"
      },
      "outputs": [],
      "source": [
        "class EmailAgents():\n",
        "    def make_categorizer_agent(self):\n",
        "        return Agent(\n",
        "            role='Email Categorizer Agent',\n",
        "            goal=\"\"\"take in a email from a human that has emailed out company email address and categorize it \\\n",
        "            into one of the following categories: \\\n",
        "            price_equiry - used when someone is asking for information about pricing \\\n",
        "            customer_complaint - used when someone is complaining about something \\\n",
        "            product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
        "            customer_feedback - used when someone is giving feedback about a product \\\n",
        "            off_topic when it doesnt relate to any other category \"\"\",\n",
        "            backstory=\"\"\"You are a master at understanding what a customer wants when they write an email and are able to categorize it in a useful way\"\"\",\n",
        "            llm=GROQ_LLM,\n",
        "            verbose=True,\n",
        "            allow_delegation=False,\n",
        "            max_iter=5,\n",
        "            memory=True,\n",
        "            step_callback=lambda x: print_agent_output(x,\"Email Categorizer Agent\"),\n",
        "        )\n",
        "\n",
        "    def make_researcher_agent(self):\n",
        "        return Agent(\n",
        "            role='Info Researcher Agent',\n",
        "            goal=\"\"\"take in a email from a human that has emailed out company email address and the category \\\n",
        "            that the categorizer agent gave it and decide what information you need to search for for the email writer to reply to \\\n",
        "            the email in a thoughtful and helpful way.\n",
        "            If you DONT think a search will help just reply 'NO SEARCH NEEDED'\n",
        "            If you dont find any useful info just reply 'NO USEFUL RESESARCH FOUND'\n",
        "            otherwise reply with the info you found that is useful for the email writer\n",
        "            \"\"\",\n",
        "            backstory=\"\"\"You are a master at understanding what information our email writer needs  to write a reply that \\\n",
        "            will help the customer\"\"\",\n",
        "            llm=GROQ_LLM,\n",
        "            verbose=True,\n",
        "            max_iter=5,\n",
        "            allow_delegation=False,\n",
        "            memory=True,\n",
        "            tools=[search_tool],\n",
        "            step_callback=lambda x: print_agent_output(x,\"Info Researcher Agent\"),\n",
        "        )\n",
        "\n",
        "    def make_email_writer_agent(self):\n",
        "        return Agent(\n",
        "            role='Email Writer Agent',\n",
        "            goal=\"\"\"take in a email from a human that has emailed out company email address, the category \\\n",
        "            that the categorizer agent gave it and the research from the research agent and \\\n",
        "            write a helpful email in a thoughtful and friendly way.\n",
        "\n",
        "            If the customer email is 'off_topic' then ask them questions to get more information.\n",
        "            If the customer email is 'customer_complaint' then try to assure we value them and that we are addressing their issues.\n",
        "            If the customer email is 'customer_feedback' then try to assure we value them and that we are addressing their issues.\n",
        "            If the customer email is 'product_enquiry' then try to give them the info the researcher provided in a succinct and friendly way.\n",
        "            If the customer email is 'price_equiry' then try to give the pricing info they requested.\n",
        "\n",
        "            You never make up information. that hasn't been provided by the researcher or in the email.\n",
        "            Always sign off the emails in appropriate manner and from Saatvik B Hampiholi (Your Helper.)\n",
        "            \"\"\",\n",
        "            backstory=\"\"\"You are a master at synthesizing a variety of information and writing a helpful email \\\n",
        "            that will address the customer's issues and provide them with helpful information\"\"\",\n",
        "            llm=GROQ_LLM,\n",
        "            verbose=True,\n",
        "            allow_delegation=False,\n",
        "            max_iter=5,\n",
        "            memory=True,\n",
        "            step_callback=lambda x: print_agent_output(x,\"Email Writer Agent\"),\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CxGkAovkUVK"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gYSmym8pdum"
      },
      "outputs": [],
      "source": [
        "class EmailTasks():\n",
        "    # Define your tasks with descriptions and expected outputs\n",
        "    def categorize_email(self, email_content):\n",
        "        return Task(\n",
        "            description=f\"\"\"Conduct a comprehensive analysis of the email provided and categorize into \\\n",
        "            one of the following categories:\n",
        "            price_equiry - used when someone is asking for information about pricing \\\n",
        "            customer_complaint - used when someone is complaining about something \\\n",
        "            product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
        "            customer_feedback - used when someone is giving feedback about a product \\\n",
        "            off_topic when it doesnt relate to any other category \\\n",
        "\n",
        "            EMAIL CONTENT:\\n\\n {email_content} \\n\\n\n",
        "            Output a single cetgory only\"\"\",\n",
        "            expected_output=\"\"\"A single categtory for the type of email from the types ('price_equiry', 'customer_complaint', 'product_enquiry', 'customer_feedback', 'off_topic') \\\n",
        "            eg:\n",
        "            'price_enquiry' \\\n",
        "            \"\"\",\n",
        "            output_file=f\"email_category.txt\",\n",
        "            agent=categorizer_agent\n",
        "            )\n",
        "\n",
        "    def research_info_for_email(self, email_content):\n",
        "        return Task(\n",
        "            description=f\"\"\"Conduct a comprehensive analysis of the email provided and the category \\\n",
        "            provided and search the web to find info needed to respond to the email\n",
        "\n",
        "            EMAIL CONTENT:\\n\\n {email_content} \\n\\n\n",
        "            Only provide the info needed DONT try to write the email\"\"\",\n",
        "            expected_output=\"\"\"A set of bullet points of useful info for the email writer \\\n",
        "            or clear instructions that no useful material was found.\"\"\",\n",
        "            context = [categorize_email],\n",
        "            output_file=f\"research_info.txt\",\n",
        "            agent=researcher_agent\n",
        "            )\n",
        "\n",
        "    def draft_email(self, email_content):\n",
        "        return Task(\n",
        "            description=f\"\"\"Conduct a comprehensive analysis of the email provided, the category provided\\\n",
        "            and the info provided from the research specialist to write an email. \\\n",
        "\n",
        "            Write a simple, polite and too the point email which will respond to the customer's email. \\\n",
        "            If useful use the info provided from the research specialist in the email. \\\n",
        "\n",
        "            If no useful info was provided from the research specialist the answer politely but don't make up info. \\\n",
        "\n",
        "            EMAIL CONTENT:\\n\\n {email_content} \\n\\n\n",
        "            Output a single cetgory only\"\"\",\n",
        "            expected_output=\"\"\"A well crafted email for the customer that addresses their issues and concerns\"\"\",\n",
        "            context = [categorize_email, research_info_for_email],\n",
        "            agent=email_writer_agent,\n",
        "            output_file=f\"draft_email.txt\",\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4xowf-0qXzf"
      },
      "source": [
        "## Instantiate Agents and Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkeN5x8aLxdO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f3ce57-4c89-4810-a609-da0eb4a8bac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter email (or type 'exit' to quit): exit\n",
            "Exiting...\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    EMAIL = input(\"Enter email (or type 'exit' to quit): \")\n",
        "    if EMAIL.lower() == 'exit':\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    agents = EmailAgents()\n",
        "    tasks = EmailTasks()\n",
        "\n",
        "    categorizer_agent = agents.make_categorizer_agent()\n",
        "    researcher_agent = agents.make_researcher_agent()\n",
        "    email_writer_agent = agents.make_email_writer_agent()\n",
        "\n",
        "    categorize_email = tasks.categorize_email(EMAIL)\n",
        "    research_info_for_email = tasks.research_info_for_email(EMAIL)\n",
        "    draft_email = tasks.draft_email(EMAIL)\n",
        "\n",
        "    crew = Crew(\n",
        "        agents=[categorizer_agent, researcher_agent, email_writer_agent],\n",
        "        tasks=[categorize_email, research_info_for_email, draft_email],\n",
        "        verbose=2,\n",
        "        process=Process.sequential,\n",
        "        full_output=True,\n",
        "        share_crew=False,\n",
        "        step_callback=lambda x: print_agent_output(x, \"MasterCrew Agent\")\n",
        "    )\n",
        "\n",
        "    results = crew.kickoff()\n",
        "\n",
        "    print(\"Crew Work Results:\")\n",
        "    print(results)\n",
        "\n",
        "    print(crew.usage_metrics)\n",
        "\n",
        "    with open('draft_email.txt', 'r') as file:\n",
        "        print(file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EoJZJyTOPY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ebf737-e788-4779-fe12-2f9d57ae04f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.110.3)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.0 (from gradio)\n",
            "  Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=a242c275e20db9ca33205fab0b8692bd27546aafe4b633a0351a9fa1331f9119\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, aiofiles, typer, gradio-client, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 12.0\n",
            "    Uninstalling websockets-12.0:\n",
            "      Successfully uninstalled websockets-12.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "instructor 0.5.2 requires typer<0.10.0,>=0.9.0, but you have typer 0.12.3 which is incompatible.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 ffmpy-0.3.2 gradio-4.28.3 gradio-client-0.16.0 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 tomlkit-0.12.0 typer-0.12.3 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIYtDvizIIXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c27e2157-836b-4479-d90f-6b7ce4bc3394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter email (or type 'exit' to quit): hi i need help. thank you\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Email Categorizer Agent\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct a comprehensive analysis of the email provided and categorize into             one of the following categories:\n",
            "            price_equiry - used when someone is asking for information about pricing             customer_complaint - used when someone is complaining about something             product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\n",
            "            customer_feedback - used when someone is giving feedback about a product             off_topic when it doesnt relate to any other category \n",
            "            EMAIL CONTENT:\n",
            "\n",
            " hi i need help. thank you \n",
            "\n",
            "\n",
            "            Output a single cetgory only\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: After conducting a comprehensive analysis of the email, I noticed that the email is very brief and lacks specific details. However, the phrase \"hi i need help\" suggests that the sender is reaching out for assistance or guidance, but it's unclear what specific issue they need help with. \n",
            "\n",
            "Final Answer: off_topic\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Email Categorizer Agent] Task output: off_topic\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Info Researcher Agent\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct a comprehensive analysis of the email provided and the category             provided and search the web to find info needed to respond to the email\n",
            "\n",
            "            EMAIL CONTENT:\n",
            "\n",
            " hi i need help. thank you \n",
            "\n",
            "\n",
            "            Only provide the info needed DONT try to write the email\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The email is very brief and lacks specific details, but I need to find a way to help the customer. \n",
            "\n",
            "Action: duckduckgo_search\n",
            "Action Input: {\"q\": \"common customer service responses to 'hi i need help'\"}\u001b[0m\u001b[91m \n",
            "\n",
            "I encountered an error while trying to use the tool. This was the error: DuckDuckGoSearchRun._run() got an unexpected keyword argument 'q'.\n",
            " Tool duckduckgo_search accepts these inputs: A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: The error message indicates that the input format is incorrect. I need to retry the search with a correct input format.\n",
            "\n",
            "Action: duckduckgo_search\n",
            "Action Input: \"common customer service responses to 'hi i need help'\"\u001b[0m\u001b[32;1m\u001b[1;3mThought: I need to retry the search with a correct input format.\n",
            "\n",
            "Action: duckduckgo_search\n",
            "Action Input: {\"query\": \"common customer service responses to 'hi i need help'\"}\u001b[0m\u001b[95m \n",
            "\n",
            "15. Follow-up response. Providing a follow-up response is a good idea for any previous customer interaction. This shows that you care about their experience and can provide great service. In a follow-up email, remind the customer of the issue that they shared, ask if they resolved the issue and offer additional help. Offer to contact the delivery provider and pass on more detail about how the delivery process works. 9. \"I'm not doing your job for you.\" Your customer has a tricky problem, but they refuse to provide you with the troubleshooting information you need to help them. Chapter 1 - Live Chat Support 101: Definition, Benefits, and Best Practices. Chapter 2 - Key Live Chat Statistics for Customer Service Teams. Chapter 3 - How to Implement Live Chat With a Small Support Team. Chapter 4 - The Big Benefits of Live Chat for Customer Service Teams. Chapter 5 - Important Live Chat Tips for Email Support Pros. 20. Broken Product or Service Email Template. If your product or service is broken, the least you can do is keep your concerned or angry customers in the loop. Resolving issues related to broken products can sharpen your customer service skills and help you build a better relationship with customers. Keeping a vault of ready-to-use customer service email templates handy can save you a lot of time, cut down your team's response times, improve your customer satisfaction, and help to provide consistent service. From dealing with complaints, and nudging along subscriptions, to guiding customers through trials, we've provided 8 customer ...\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: \n",
            "* The customer is seeking help, but no specific details are provided. \n",
            "* A response acknowledging their request and asking for more information about their issue would be appropriate. \n",
            "* A follow-up response can be sent to ensure the customer's issue is resolved and offer additional help if needed.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Info Researcher Agent] Task output: * The customer is seeking help, but no specific details are provided. \n",
            "* A response acknowledging their request and asking for more information about their issue would be appropriate. \n",
            "* A follow-up response can be sent to ensure the customer's issue is resolved and offer additional help if needed.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Email Writer Agent\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct a comprehensive analysis of the email provided, the category provided            and the info provided from the research specialist to write an email. \n",
            "            Write a simple, polite and too the point email which will respond to the customer's email.             If useful use the info provided from the research specialist in the email. \n",
            "            If no useful info was provided from the research specialist the answer politely but don't make up info. \n",
            "            EMAIL CONTENT:\n",
            "\n",
            " hi i need help. thank you \n",
            "\n",
            "\n",
            "            Output a single cetgory only\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "Dear [Customer],\n",
            "\n",
            "Thank you for reaching out to us for help. We're happy to assist you with any issues or concerns you may have. However, to better understand your situation, could you please provide more details about what you need help with? This will enable us to provide a more effective and personalized solution for you.\n",
            "\n",
            "Please feel free to share as much information as possible, and we'll do our best to respond promptly and efficiently.\n",
            "\n",
            "Thank you for your patience and cooperation. We look forward to hearing back from you and resolving your issue.\n",
            "\n",
            "Best regards,\n",
            "Saatvik B Hampiholi (Your Helper)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Email Writer Agent] Task output: Dear [Customer],\n",
            "\n",
            "Thank you for reaching out to us for help. We're happy to assist you with any issues or concerns you may have. However, to better understand your situation, could you please provide more details about what you need help with? This will enable us to provide a more effective and personalized solution for you.\n",
            "\n",
            "Please feel free to share as much information as possible, and we'll do our best to respond promptly and efficiently.\n",
            "\n",
            "Thank you for your patience and cooperation. We look forward to hearing back from you and resolving your issue.\n",
            "\n",
            "Best regards,\n",
            "Saatvik B Hampiholi (Your Helper)\n",
            "\n",
            "\u001b[00m\n",
            "Crew Work Results:\n",
            "{'final_output': \"Dear [Customer],\\n\\nThank you for reaching out to us for help. We're happy to assist you with any issues or concerns you may have. However, to better understand your situation, could you please provide more details about what you need help with? This will enable us to provide a more effective and personalized solution for you.\\n\\nPlease feel free to share as much information as possible, and we'll do our best to respond promptly and efficiently.\\n\\nThank you for your patience and cooperation. We look forward to hearing back from you and resolving your issue.\\n\\nBest regards,\\nSaatvik B Hampiholi (Your Helper)\", 'tasks_outputs': [TaskOutput(description='Conduct a comprehensive analysis of the email provided and categorize into             one of the following categories:\\n            price_equiry - used when someone is asking for information about pricing             customer_complaint - used when someone is complaining about something             product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\\n            customer_feedback - used when someone is giving feedback about a product             off_topic when it doesnt relate to any other category \\n            EMAIL CONTENT:\\n\\n hi i need help. thank you \\n\\n\\n            Output a single cetgory only', summary='Conduct a comprehensive analysis of the email provided and categorize...', exported_output='off_topic', raw_output='off_topic'), TaskOutput(description='Conduct a comprehensive analysis of the email provided and the category             provided and search the web to find info needed to respond to the email\\n\\n            EMAIL CONTENT:\\n\\n hi i need help. thank you \\n\\n\\n            Only provide the info needed DONT try to write the email', summary='Conduct a comprehensive analysis of the email provided and the...', exported_output=\"* The customer is seeking help, but no specific details are provided. \\n* A response acknowledging their request and asking for more information about their issue would be appropriate. \\n* A follow-up response can be sent to ensure the customer's issue is resolved and offer additional help if needed.\", raw_output=\"* The customer is seeking help, but no specific details are provided. \\n* A response acknowledging their request and asking for more information about their issue would be appropriate. \\n* A follow-up response can be sent to ensure the customer's issue is resolved and offer additional help if needed.\"), TaskOutput(description=\"Conduct a comprehensive analysis of the email provided, the category provided            and the info provided from the research specialist to write an email. \\n            Write a simple, polite and too the point email which will respond to the customer's email.             If useful use the info provided from the research specialist in the email. \\n            If no useful info was provided from the research specialist the answer politely but don't make up info. \\n            EMAIL CONTENT:\\n\\n hi i need help. thank you \\n\\n\\n            Output a single cetgory only\", summary='Conduct a comprehensive analysis of the email provided, the category...', exported_output=\"Dear [Customer],\\n\\nThank you for reaching out to us for help. We're happy to assist you with any issues or concerns you may have. However, to better understand your situation, could you please provide more details about what you need help with? This will enable us to provide a more effective and personalized solution for you.\\n\\nPlease feel free to share as much information as possible, and we'll do our best to respond promptly and efficiently.\\n\\nThank you for your patience and cooperation. We look forward to hearing back from you and resolving your issue.\\n\\nBest regards,\\nSaatvik B Hampiholi (Your Helper)\", raw_output=\"Dear [Customer],\\n\\nThank you for reaching out to us for help. We're happy to assist you with any issues or concerns you may have. However, to better understand your situation, could you please provide more details about what you need help with? This will enable us to provide a more effective and personalized solution for you.\\n\\nPlease feel free to share as much information as possible, and we'll do our best to respond promptly and efficiently.\\n\\nThank you for your patience and cooperation. We look forward to hearing back from you and resolving your issue.\\n\\nBest regards,\\nSaatvik B Hampiholi (Your Helper)\")]}\n",
            "{'total_tokens': 40770, 'prompt_tokens': 37008, 'completion_tokens': 3762, 'successful_requests': 54}\n",
            "Dear [Customer],\n",
            "\n",
            "Thank you for reaching out to us for help. We're happy to assist you with any issues or concerns you may have. However, to better understand your situation, could you please provide more details about what you need help with? This will enable us to provide a more effective and personalized solution for you.\n",
            "\n",
            "Please feel free to share as much information as possible, and we'll do our best to respond promptly and efficiently.\n",
            "\n",
            "Thank you for your patience and cooperation. We look forward to hearing back from you and resolving your issue.\n",
            "\n",
            "Best regards,\n",
            "Saatvik B Hampiholi (Your Helper)\n",
            "Enter email (or type 'exit' to quit): exit\n",
            "Exiting...\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://efd18df5554f0813c9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://efd18df5554f0813c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from crewai import Crew, Process\n",
        "\n",
        "class EmailAgents:\n",
        "    # Define EmailAgents class as before\n",
        "    def make_categorizer_agent(self):\n",
        "        return Agent(\n",
        "            role='Email Categorizer Agent',\n",
        "            goal=\"\"\"take in a email from a human that has emailed out company email address and categorize it \\\n",
        "            into one of the following categories: \\\n",
        "            price_equiry - used when someone is asking for information about pricing \\\n",
        "            customer_complaint - used when someone is complaining about something \\\n",
        "            product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
        "            customer_feedback - used when someone is giving feedback about a product \\\n",
        "            off_topic when it doesnt relate to any other category \"\"\",\n",
        "            backstory=\"\"\"You are a master at understanding what a customer wants when they write an email and are able to categorize it in a useful way\"\"\",\n",
        "            llm=GROQ_LLM,\n",
        "            verbose=True,\n",
        "            allow_delegation=False,\n",
        "            max_iter=5,\n",
        "            memory=True,\n",
        "            step_callback=lambda x: print_agent_output(x,\"Email Categorizer Agent\"),\n",
        "        )\n",
        "\n",
        "    def make_researcher_agent(self):\n",
        "        return Agent(\n",
        "            role='Info Researcher Agent',\n",
        "            goal=\"\"\"take in a email from a human that has emailed out company email address and the category \\\n",
        "            that the categorizer agent gave it and decide what information you need to search for for the email writer to reply to \\\n",
        "            the email in a thoughtful and helpful way.\n",
        "            If you DONT think a search will help just reply 'NO SEARCH NEEDED'\n",
        "            If you dont find any useful info just reply 'NO USEFUL RESESARCH FOUND'\n",
        "            otherwise reply with the info you found that is useful for the email writer\n",
        "            \"\"\",\n",
        "            backstory=\"\"\"You are a master at understanding what information our email writer needs  to write a reply that \\\n",
        "            will help the customer\"\"\",\n",
        "            llm=GROQ_LLM,\n",
        "            verbose=True,\n",
        "            max_iter=5,\n",
        "            allow_delegation=False,\n",
        "            memory=True,\n",
        "            tools=[search_tool],\n",
        "            step_callback=lambda x: print_agent_output(x,\"Info Researcher Agent\"),\n",
        "        )\n",
        "\n",
        "    def make_email_writer_agent(self):\n",
        "        return Agent(\n",
        "            role='Email Writer Agent',\n",
        "            goal=\"\"\"take in a email from a human that has emailed out company email address, the category \\\n",
        "            that the categorizer agent gave it and the research from the research agent and \\\n",
        "            write a helpful email in a thoughtful and friendly way.\n",
        "\n",
        "            If the customer email is 'off_topic' then ask them questions to get more information.\n",
        "            If the customer email is 'customer_complaint' then try to assure we value them and that we are addressing their issues.\n",
        "            If the customer email is 'customer_feedback' then try to assure we value them and that we are addressing their issues.\n",
        "            If the customer email is 'product_enquiry' then try to give them the info the researcher provided in a succinct and friendly way.\n",
        "            If the customer email is 'price_equiry' then try to give the pricing info they requested.\n",
        "\n",
        "            You never make up information. that hasn't been provided by the researcher or in the email.\n",
        "            Always sign off the emails in appropriate manner and from Saatvik B Hampiholi (Your Helper.)\n",
        "            \"\"\",\n",
        "            backstory=\"\"\"You are a master at synthesizing a variety of information and writing a helpful email \\\n",
        "            that will address the customer's issues and provide them with helpful information\"\"\",\n",
        "            llm=GROQ_LLM,\n",
        "            verbose=True,\n",
        "            allow_delegation=False,\n",
        "            max_iter=5,\n",
        "            memory=True,\n",
        "            step_callback=lambda x: print_agent_output(x,\"Email Writer Agent\"),\n",
        "        )\n",
        "\n",
        "class EmailTasks:\n",
        "    # Define EmailTasks class as before\n",
        "    def categorize_email(self, email_content):\n",
        "        return Task(\n",
        "            description=f\"\"\"Conduct a comprehensive analysis of the email provided and categorize into \\\n",
        "            one of the following categories:\n",
        "            price_equiry - used when someone is asking for information about pricing \\\n",
        "            customer_complaint - used when someone is complaining about something \\\n",
        "            product_enquiry - used when someone is asking for information about a product feature, benefit or service but not about pricing \\\\\n",
        "            customer_feedback - used when someone is giving feedback about a product \\\n",
        "            off_topic when it doesnt relate to any other category \\\n",
        "\n",
        "            EMAIL CONTENT:\\n\\n {email_content} \\n\\n\n",
        "            Output a single cetgory only\"\"\",\n",
        "            expected_output=\"\"\"A single categtory for the type of email from the types ('price_equiry', 'customer_complaint', 'product_enquiry', 'customer_feedback', 'off_topic') \\\n",
        "            eg:\n",
        "            'price_enquiry' \\\n",
        "            \"\"\",\n",
        "            output_file=f\"email_category.txt\",\n",
        "            agent=categorizer_agent\n",
        "        )\n",
        "\n",
        "    def research_info_for_email(self, email_content):\n",
        "        return Task(\n",
        "            description=f\"\"\"Conduct a comprehensive analysis of the email provided and the category \\\n",
        "            provided and search the web to find info needed to respond to the email\n",
        "\n",
        "            EMAIL CONTENT:\\n\\n {email_content} \\n\\n\n",
        "            Only provide the info needed DONT try to write the email\"\"\",\n",
        "            expected_output=\"\"\"A set of bullet points of useful info for the email writer \\\n",
        "            or clear instructions that no useful material was found.\"\"\",\n",
        "            context=[categorize_email],\n",
        "            output_file=f\"research_info.txt\",\n",
        "            agent=researcher_agent\n",
        "        )\n",
        "\n",
        "    def draft_email(self, email_content):\n",
        "        return Task(\n",
        "            description=f\"\"\"Conduct a comprehensive analysis of the email provided, the category provided\\\n",
        "            and the info provided from the research specialist to write an email. \\\n",
        "\n",
        "            Write a simple, polite and too the point email which will respond to the customer's email. \\\n",
        "            If useful use the info provided from the research specialist in the email. \\\n",
        "\n",
        "            If no useful info was provided from the research specialist the answer politely but don't make up info. \\\n",
        "\n",
        "            EMAIL CONTENT:\\n\\n {email_content} \\n\\n\n",
        "            Output a single cetgory only\"\"\",\n",
        "            expected_output=\"\"\"A well crafted email for the customer that addresses their issues and concerns\"\"\",\n",
        "            context=[categorize_email, research_info_for_email],\n",
        "            agent=email_writer_agent,\n",
        "            output_file=f\"draft_email.txt\",\n",
        "        )\n",
        "\n",
        "def print_agent_output(output, agent_name):\n",
        "    # Define print_agent_output function as before\n",
        "    pass\n",
        "\n",
        "while True:\n",
        "    EMAIL = input(\"Enter email (or type 'exit' to quit): \")\n",
        "    if EMAIL.lower() == 'exit':\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    agents = EmailAgents()\n",
        "    tasks = EmailTasks()\n",
        "\n",
        "    categorizer_agent = agents.make_categorizer_agent()\n",
        "    researcher_agent = agents.make_researcher_agent()\n",
        "    email_writer_agent = agents.make_email_writer_agent()\n",
        "\n",
        "    categorize_email = tasks.categorize_email(EMAIL)\n",
        "    research_info_for_email = tasks.research_info_for_email(EMAIL)\n",
        "    draft_email = tasks.draft_email(EMAIL)\n",
        "\n",
        "    crew = Crew(\n",
        "        agents=[categorizer_agent, researcher_agent, email_writer_agent],\n",
        "        tasks=[categorize_email, research_info_for_email, draft_email],\n",
        "        verbose=2,\n",
        "        process=Process.sequential,\n",
        "        full_output=True,\n",
        "        share_crew=False,\n",
        "        step_callback=lambda x: print_agent_output(x, \"MasterCrew Agent\")\n",
        "    )\n",
        "\n",
        "    results = crew.kickoff()\n",
        "\n",
        "    print(\"Crew Work Results:\")\n",
        "    print(results)\n",
        "\n",
        "    print(crew.usage_metrics)\n",
        "\n",
        "    with open('draft_email.txt', 'r') as file:\n",
        "        print(file.read())\n",
        "\n",
        "def process_email(email):\n",
        "    agents = EmailAgents()\n",
        "    tasks = EmailTasks()\n",
        "\n",
        "    categorizer_agent = agents.make_categorizer_agent()\n",
        "    researcher_agent = agents.make_researcher_agent()\n",
        "    email_writer_agent = agents.make_email_writer_agent()\n",
        "\n",
        "    categorize_email = tasks.categorize_email(email)\n",
        "    research_info_for_email = tasks.research_info_for_email(email)\n",
        "    draft_email = tasks.draft_email(email)\n",
        "\n",
        "    crew = Crew(\n",
        "        agents=[categorizer_agent, researcher_agent, email_writer_agent],\n",
        "        tasks=[categorize_email, research_info_for_email, draft_email],\n",
        "        verbose=2,\n",
        "        process=Process.sequential,\n",
        "        full_output=True,\n",
        "        share_crew=False,\n",
        "        step_callback=lambda x: print_agent_output(x, \"MasterCrew Agent\")\n",
        "    )\n",
        "\n",
        "    results = crew.kickoff()\n",
        "\n",
        "    with open('draft_email.txt', 'r') as file:\n",
        "        email_output = file.read()\n",
        "\n",
        "    return email_output\n",
        "\n",
        "iface = gr.Interface(fn=process_email, inputs=\"text\", outputs=\"text\", title=\"Email Processing\", description=\"Enter your email to generate a response.\")\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-a1LrsDObnU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}